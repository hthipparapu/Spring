{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ba1ae1-b2a6-428e-8aab-937a11f910e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19dde64e-72f9-4575-b43d-3dca74579f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-1.3.5-cp37-cp37m-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2017.3 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Downloading pandas-1.3.5-cp37-cp37m-win_amd64.whl (10.0 MB)\n",
      "   ---------------------------------------- 10.0/10.0 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "   --------------------------------------- 509.2/509.2 kB 10.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.3.5 pytz-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9016f24-09aa-43c9-ab5c-6acaade9a4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.3-cp37-cp37m-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl.metadata (138 kB)\n",
      "     -------------------------------------- 138.5/138.5 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp37-cp37m-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib) (22.0)\n",
      "Collecting pillow>=6.2.0 (from matplotlib)\n",
      "  Downloading Pillow-9.5.0-cp37-cp37m-win_amd64.whl.metadata (9.7 kB)\n",
      "Collecting pyparsing>=2.2.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.5.3-cp37-cp37m-win_amd64.whl (7.2 MB)\n",
      "   ---------------------------------------- 7.2/7.2 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "   --------------------------------------- 965.4/965.4 kB 10.3 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp37-cp37m-win_amd64.whl (55 kB)\n",
      "   ---------------------------------------- 55.8/55.8 kB ? eta 0:00:00\n",
      "Downloading Pillow-9.5.0-cp37-cp37m-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 2.5/2.5 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "   ---------------------------------------- 104.1/104.1 kB ? eta 0:00:00\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.5 matplotlib-3.5.3 pillow-9.5.0 pyparsing-3.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079e713a-4aeb-4b5c-8f37-81b25d6f4137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from seaborn) (1.21.6)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from seaborn) (3.5.3)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from seaborn) (4.7.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from pandas>=0.25->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "   ---------------------------------------- 293.3/293.3 kB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4520cde2-d3c7-4347-a8d5-912228e00c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af46c0fa-c62a-4526-ae18-bc0425f7c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from scikit-learn) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\harit\\anaconda3\\envs\\testenv\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Downloading scikit_learn-1.0.2-cp37-cp37m-win_amd64.whl (7.1 MB)\n",
      "   ---------------------------------------- 7.1/7.1 MB 6.5 MB/s eta 0:00:00\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.0.2 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96835bdd-0006-458d-8cdc-c1ddc452a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25ed6615-1efa-492f-b6fb-b2f32b3118a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged metrics: dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n",
      "Logged metrics: dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n",
      "Logged metrics: dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n",
      "Logged metrics: dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n",
      "Logged metrics: dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n",
      "Logged metrics: dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n",
      "   Data size  Hidden layers  Training accuracy  Validation accuracy  \\\n",
      "0       1000              1             0.7812               0.7450   \n",
      "1       1000              2             0.7762               0.7450   \n",
      "2      10000              1             0.9965               0.9955   \n",
      "3      10000              2             0.9969               0.9980   \n",
      "4     100000              1             0.9988               0.9986   \n",
      "5     100000              2             0.9985               0.9976   \n",
      "\n",
      "   Execution time (s)  \n",
      "0                2.02  \n",
      "1                2.30  \n",
      "2               10.37  \n",
      "3               11.46  \n",
      "4              101.72  \n",
      "5              269.82  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"patientdata.csv\")\n",
    "\n",
    "# Function to bootstrap the data\n",
    "def bootstrap_data(df, size):\n",
    "    return df.sample(n=size, replace=True, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Function to scale and split data\n",
    "def prepare_data(df):\n",
    "    X = df.drop(columns=[\"outcome\"]).values\n",
    "    y = df[\"outcome\"].values\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    return X_train_scaled, X_val_scaled, y_train, y_val\n",
    "\n",
    "def run_dl_model(data, hidden_layers):\n",
    "    X_train, X_val, y_train, y_val = prepare_data(data)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=X_train.shape[1], activation='relu'))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "\n",
    "    start = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20, batch_size=32,\n",
    "        verbose=0,\n",
    "        validation_data=(X_val, y_val)\n",
    "    )\n",
    "    end = time.time()\n",
    "\n",
    "    # Retrieve metrics safely\n",
    "    hist_keys = history.history.keys()\n",
    "    print(f\"Logged metrics: {hist_keys}\")  # Remove this after confirming it works\n",
    "\n",
    "    # Handle both naming conventions\n",
    "    train_acc = history.history.get('accuracy', history.history.get('acc'))[-1]\n",
    "    val_acc = history.history.get('val_accuracy', history.history.get('val_acc'))[-1]\n",
    "    duration = round(end - start, 2)\n",
    "\n",
    "    return train_acc, val_acc, duration\n",
    "\n",
    "\n",
    "# Test sizes and configs\n",
    "sizes = [1000, 10000, 100000]\n",
    "results = []\n",
    "\n",
    "# Run deep learning models\n",
    "for size in sizes:\n",
    "    boot_df = bootstrap_data(df, size)\n",
    "    for layers in [1, 2]:\n",
    "        train_acc, val_acc, duration = run_dl_model(boot_df, hidden_layers=layers)\n",
    "        results.append({\n",
    "            \"Data size\": size,\n",
    "            \"Hidden layers\": layers,\n",
    "            \"Training accuracy\": round(train_acc, 4),\n",
    "            \"Validation accuracy\": round(val_acc, 4),\n",
    "            \"Execution time (s)\": duration\n",
    "        })\n",
    "\n",
    "# Output result table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28667a78-384c-4e22-83c4-7355449934e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
