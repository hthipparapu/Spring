{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac62e995-4340-427b-afc4-8afa9d157438",
   "metadata": {},
   "source": [
    "## Haritha Thipparapu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd036857-1fd2-4e39-a5c4-a672801c7829",
   "metadata": {},
   "source": [
    "## Week 09 - Machine Learning with Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70dd8c-f028-49c0-8b27-1b52e2055940",
   "metadata": {},
   "source": [
    "## 1. Among the different classification models included in the Python notebook, which model had the best overall performance? Support your response by referencing appropriate evidence.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b3b86-87bc-4897-b5bb-4368d6682712",
   "metadata": {},
   "source": [
    "#### In the results section of the notebook:\n",
    "\n",
    "Random Forest delivered superior performance by achieving the best evaluation accuracy which exceeded the scores of Decision Tree, k-Nearest Neighbors and Logistic Regression.\n",
    "\n",
    "The generalization ability of Random Forest proved superior since it maintained better alignment between training and testing accuracy and outperformed both k-NN and Decision Trees and Logistic Regression at interpreting data patterns.\n",
    "\n",
    "The notebook outputs demonstrate this example.\n",
    "\n",
    "Random Forest Accuracy:\n",
    "\n",
    "The ensemble model exhibited Training Accuracy at ~1.00 since ensemble techniques demonstrate this characteristic.\n",
    "\n",
    "Test Accuracy: ~0.83\n",
    "\n",
    "In comparison:\n",
    "\n",
    "Logistic Regression Test Accuracy: ~0.79\n",
    "\n",
    "k-NN Test Accuracy: ~0.74\n",
    "\n",
    "Decision Tree Test Accuracy: ~0.78\n",
    "\n",
    "The Random Forest classification report along with confusion matrix demonstrated robust performance across various classes because it achieved precise and accurate results.\n",
    "\n",
    "#### Conclusion:\n",
    "Among the models under evaluation in the notebook the Random Forest Classifier produced the best performance results due to its high test accuracy rates together with balanced performance and strong generalization capabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdda498-765c-4b72-9178-348624e8cf12",
   "metadata": {},
   "source": [
    "## 2. Fit a series of logistic regression models, without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9ae55e8-700d-4570-b8b1-77ac8ad5c36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Myocardial_infarction</th>\n",
       "      <th>Congestive_heart_failure</th>\n",
       "      <th>Peripheral_vascular_disease</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Dementia</th>\n",
       "      <th>Pulmonary</th>\n",
       "      <th>...</th>\n",
       "      <th>Metastatic_solid_tumour</th>\n",
       "      <th>HIV</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>First_Appointment_Date</th>\n",
       "      <th>Last_Appointment_Date</th>\n",
       "      <th>DateOfDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1962-02-27</td>\n",
       "      <td>female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-27</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1959-08-18</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-11-30</td>\n",
       "      <td>2008-11-02</td>\n",
       "      <td>2008-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1946-02-15</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-11-05</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1979-07-27</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>2016-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1983-02-19</td>\n",
       "      <td>female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-09-22</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>19996</td>\n",
       "      <td>1997-12-19</td>\n",
       "      <td>female</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-06-14</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19997</td>\n",
       "      <td>1984-03-31</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-04-24</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19998</td>\n",
       "      <td>1993-07-04</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-16</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>19999</td>\n",
       "      <td>1984-04-17</td>\n",
       "      <td>male</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>20000</td>\n",
       "      <td>1966-05-14</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-04-01</td>\n",
       "      <td>2012-05-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PatientID DateOfBirth  Gender      Race  Myocardial_infarction  \\\n",
       "0              1  1962-02-27  female  hispanic                      0   \n",
       "1              2  1959-08-18    male     white                      0   \n",
       "2              3  1946-02-15  female     white                      0   \n",
       "3              4  1979-07-27  female     white                      0   \n",
       "4              5  1983-02-19  female  hispanic                      0   \n",
       "...          ...         ...     ...       ...                    ...   \n",
       "19995      19996  1997-12-19  female     other                      0   \n",
       "19996      19997  1984-03-31  female     white                      0   \n",
       "19997      19998  1993-07-04  female     white                      0   \n",
       "19998      19999  1984-04-17    male     other                      0   \n",
       "19999      20000  1966-05-14  female     white                      0   \n",
       "\n",
       "       Congestive_heart_failure  Peripheral_vascular_disease  Stroke  \\\n",
       "0                             0                            0       0   \n",
       "1                             0                            0       0   \n",
       "2                             0                            0       0   \n",
       "3                             0                            0       0   \n",
       "4                             0                            0       0   \n",
       "...                         ...                          ...     ...   \n",
       "19995                         0                            0       0   \n",
       "19996                         0                            0       0   \n",
       "19997                         0                            0       0   \n",
       "19998                         0                            0       0   \n",
       "19999                         0                            0       0   \n",
       "\n",
       "       Dementia  Pulmonary  ...  Metastatic_solid_tumour  HIV  Obesity  \\\n",
       "0             0          0  ...                        0    0        0   \n",
       "1             0          0  ...                        0    0        0   \n",
       "2             0          0  ...                        0    1        0   \n",
       "3             0          1  ...                        0    0        0   \n",
       "4             0          0  ...                        0    0        0   \n",
       "...         ...        ...  ...                      ...  ...      ...   \n",
       "19995         0          0  ...                        0    0        0   \n",
       "19996         0          0  ...                        0    1        0   \n",
       "19997         0          0  ...                        0    0        1   \n",
       "19998         0          0  ...                        0    0        0   \n",
       "19999         0          0  ...                        0    0        0   \n",
       "\n",
       "       Depression  Hypertension  Drugs  Alcohol  First_Appointment_Date  \\\n",
       "0               0             0      0        0              2013-04-27   \n",
       "1               0             1      0        0              2005-11-30   \n",
       "2               0             1      0        0              2011-11-05   \n",
       "3               0             0      0        0              2010-03-01   \n",
       "4               0             1      0        0              2006-09-22   \n",
       "...           ...           ...    ...      ...                     ...   \n",
       "19995           0             0      0        0              2008-06-14   \n",
       "19996           0             1      0        0              2007-04-24   \n",
       "19997           0             1      0        0              2010-10-16   \n",
       "19998           0             1      0        0              2015-01-04   \n",
       "19999           0             0      1        0              2011-04-01   \n",
       "\n",
       "       Last_Appointment_Date  DateOfDeath  \n",
       "0                 2018-06-01          NaN  \n",
       "1                 2008-11-02   2008-11-02  \n",
       "2                 2015-11-13          NaN  \n",
       "3                 2016-01-17   2016-01-17  \n",
       "4                 2018-06-01          NaN  \n",
       "...                      ...          ...  \n",
       "19995             2018-06-01          NaN  \n",
       "19996             2018-06-01          NaN  \n",
       "19997             2018-06-01          NaN  \n",
       "19998             2018-06-01          NaN  \n",
       "19999             2012-05-16          NaN  \n",
       "\n",
       "[20000 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set print limits\n",
    "pd.options.display.max_rows = 10\n",
    "## Import Data\n",
    "df_patient = \\\n",
    " pd.read_csv('./PatientAnalyticFile.csv')\n",
    "df_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8cc59b7-1c5d-4aca-8320-1a44cacf461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Solver  Training Accuracy  Holdout Accuracy  Time Taken (seconds)\n",
      "newton-cg           0.748062           0.73550              0.184598\n",
      "    lbfgs           0.748188           0.73575              0.277604\n",
      "liblinear           0.747938           0.73625              0.086682\n",
      "      sag           0.747938           0.73575              2.179397\n",
      "     saga           0.748000           0.73600              3.238441\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from patsy import dmatrices\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the data\n",
    "df_patient = pd.read_csv('PatientAnalyticFile.csv')\n",
    "\n",
    "# Create mortality outcome: 1 if DateOfDeath exists, else 0\n",
    "df_patient['mortality'] = np.where(df_patient['DateOfDeath'].isnull(), 0, 1)\n",
    "\n",
    "# Calculate age from DateOfBirth\n",
    "df_patient['DateOfBirth'] = pd.to_datetime(df_patient['DateOfBirth'])\n",
    "df_patient['Age_years'] = ((pd.to_datetime('2015-01-01') - df_patient['DateOfBirth']).dt.days / 365.25)\n",
    "\n",
    "# Remove columns not to be used in modeling\n",
    "vars_remove = ['PatientID', 'First_Appointment_Date', 'DateOfBirth',\n",
    "               'Last_Appointment_Date', 'DateOfDeath', 'mortality']\n",
    "vars_left = set(df_patient.columns) - set(vars_remove)\n",
    "\n",
    "# Create model formula using all other variables\n",
    "formula = \"mortality ~ \" + \" + \".join(vars_left)\n",
    "\n",
    "# Create design matrices\n",
    "Y, X = dmatrices(formula, df_patient)\n",
    "\n",
    "# Split data into training and testing sets (same for all models)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, np.ravel(Y), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# List of solvers to evaluate\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_solver(solver_name, X_train, X_test, y_train, y_test):\n",
    "    start_time = time.time()\n",
    "\n",
    "    if solver_name == 'liblinear':\n",
    "        model = LogisticRegression(solver=solver_name, penalty='l2', random_state=42)\n",
    "    elif solver_name in ['sag', 'saga']:\n",
    "        model = LogisticRegression(solver=solver_name, penalty=None, random_state=42, max_iter=1000)\n",
    "    else:\n",
    "        model = LogisticRegression(solver=solver_name, penalty=None, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "    return {\n",
    "        'Solver': solver_name,\n",
    "        'Training Accuracy': train_accuracy,\n",
    "        'Holdout Accuracy': test_accuracy,\n",
    "        'Time Taken (seconds)': elapsed_time\n",
    "    }\n",
    "\n",
    "# Run evaluation for all solvers\n",
    "results = []\n",
    "for solver in solvers:\n",
    "    result = evaluate_solver(solver, X_train, X_test, y_train, y_test)\n",
    "    results.append(result)\n",
    "\n",
    "# Display results table\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[['Solver', 'Training Accuracy', 'Holdout Accuracy', 'Time Taken (seconds)']]\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c2064-ac59-4a84-b0bf-e5a62c3e0385",
   "metadata": {},
   "source": [
    "### 3. Summarize the results in table formate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "516b3c17-6751-4f85-8d08-9149bbcb3555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Solver  Training Accuracy  Holdout Accuracy  Time Taken (seconds)\n",
      "newton-cg           0.748062           0.73550              0.184598\n",
      "    lbfgs           0.748188           0.73575              0.277604\n",
      "liblinear           0.747938           0.73625              0.086682\n",
      "      sag           0.747938           0.73575              2.179397\n",
      "     saga           0.748000           0.73600              3.238441\n"
     ]
    }
   ],
   "source": [
    "# Display results table\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[['Solver', 'Training Accuracy', 'Holdout Accuracy', 'Time Taken (seconds)']]\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95a5187-9146-4479-b985-7d9a880873ef",
   "metadata": {},
   "source": [
    "### 4. Based on the results, which solver yielded the best results? Explain the basis for ranking the models - did you use training subset accuracy? Holdout subset accuracy? Time of execution? All three? Some combination of the three?\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ba5331-b7ca-468f-aafd-c4cb25d53d48",
   "metadata": {},
   "source": [
    "Interpretation of Results:\r\n",
    "Liblinear managed to achieve a maximum holdout accuracy at 0.73625 while finishing the task in 0.086682 seconds. Despite its fast operation timing the model executed with high success rate.\r\n",
    "\r\n",
    "The accuracy levels between newton-cg, lbfgs, sag and saga stood at approximately 0.735 but these models displayed distinct timing variations when executing.\r\n",
    "\r\n",
    "The liblinear solver performed the quickest among all options whereas newton-cg followed and then lbfgs then sag before saga required the most time to execute.\r\n",
    "\r\n",
    "Ranking the Models:\r\n",
    "Liblinear stands as the best selection when execution speed matters because it delivers rapid computations without reducing holdout accuracy substantially.\r\n",
    "\r\n",
    "Based on the criterion of maximal holdout set accuracy the choice between liblinear newton-cg and lbfgs should be considered equally effective.\r\n",
    "\r\n",
    "Conclusion:\r\n",
    "The liblinear solver achieved the optimal performance between accuracy and computational speed which makes it the most effective approach for logistic regression in this scenario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
